{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electoral-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "double-truck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 28, 28])\n",
      "torch.Size([5, 3, 3, 3])\n",
      "torch.Size([5])\n",
      "torch.Size([32, 5, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "N, n_H, n_W, n_C = 32, 28, 28,3\n",
    "n_filter = 5\n",
    "k_size   = 3\n",
    "\n",
    "# Torch's image tensor (N, C, H, W) \n",
    "images = torch.rand((N,n_C, n_H, n_W ))\n",
    "\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, ... )\n",
    "conv = nn.Conv2d(n_C,n_filter,k_size )\n",
    "\n",
    "y = conv(images)\n",
    "\n",
    "weight, bias = conv.weight, conv.bias\n",
    "\n",
    "print(images.shape)  \n",
    "print(weight.shape)  # N_Kernel, N_Channel, n_H, n_W\n",
    "print(bias.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-cambridge",
   "metadata": {},
   "source": [
    "## Computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "uniform-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 2, 2])\n",
      "y(torch) : \n",
      " tensor([[[[-0.2740,  0.0193],\n",
      "          [-0.0737,  0.1618]],\n",
      "\n",
      "         [[ 0.2519,  0.2198],\n",
      "          [ 0.0323,  0.4580]],\n",
      "\n",
      "         [[-0.4345, -0.0443],\n",
      "          [-0.2261,  0.0431]],\n",
      "\n",
      "         [[-0.5529, -0.9622],\n",
      "          [-0.5588, -0.8719]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "N, n_H, n_W, n_C = 1, 5, 5,3\n",
    "n_filter = 4\n",
    "k_size   = 4\n",
    "\n",
    "# Torch's image tensor (N, C, H, W) \n",
    "images = torch.rand((N,n_C, n_H, n_W ))\n",
    "\n",
    "# torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, ... )\n",
    "conv = nn.Conv2d(n_C,n_filter,k_size )\n",
    "\n",
    "y = conv(images)\n",
    "\n",
    "print(y.shape)\n",
    "print(\"y(torch) : \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "corresponding-visitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5, 5)\n",
      "(4, 3, 4, 4) (4,)\n"
     ]
    }
   ],
   "source": [
    "images = images.detach().numpy()\n",
    "print(images.shape)\n",
    "weight, bias = conv.weight.detach().numpy(), conv.bias.detach().numpy()\n",
    "print(weight.shape, bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "incomplete-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 2)\n",
      "y(torch) : \n",
      " [[[-0.274   0.0193]\n",
      "  [-0.0737  0.1618]]\n",
      "\n",
      " [[ 0.2519  0.2198]\n",
      "  [ 0.0323  0.458 ]]\n",
      "\n",
      " [[-0.4345 -0.0443]\n",
      "  [-0.2261  0.0431]]\n",
      "\n",
      " [[-0.5529 -0.9622]\n",
      "  [-0.5588 -0.8719]]]\n"
     ]
    }
   ],
   "source": [
    "y = np.zeros((n_filter, n_H-k_size+1,n_W-k_size+1))\n",
    "images = images.squeeze()\n",
    "for i in range(n_filter):\n",
    "    c_W = weight[i,:,:,:]\n",
    "    c_B = bias[i]\n",
    "    for h in range(n_H-k_size+1):\n",
    "        for w in range(n_W-k_size+1):\n",
    "            window = images[:, h:h+k_size , w:w+k_size ]\n",
    "            y[i,h,w] = np.sum( c_W * window )  + c_B\n",
    "\n",
    "print(y.shape)\n",
    "print(\"y(torch) : \\n\", np.round(y,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
