{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eastern-polish",
   "metadata": {},
   "source": [
    "## Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "other-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "binding-probe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1]) torch.Size([32, 1])\n",
      "MSE(Pytorch) :  tensor(0.1597)\n",
      "MSE          :  tensor(0.1597)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "predictions = torch.rand(batch_size,1)\n",
    "\n",
    "labels       = torch.rand(batch_size,1)\n",
    "\n",
    "print(predictions.shape, labels.shape)\n",
    "\n",
    "mse = loss(predictions, labels)\n",
    "\n",
    "print(\"MSE(Pytorch) : \", mse)\n",
    "print(\"MSE          : \", torch.mean((labels-predictions)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "voluntary-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "N, n_feature = 100, 5\n",
    "\n",
    "X = torch.rand((N,n_feature))\n",
    "Y = torch.rand((N,1))\n",
    "\n",
    "dataset    = TensorDataset(X,Y)         # create your datset\n",
    "dataloader = DataLoader(dataset)        # create your dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-saver",
   "metadata": {},
   "source": [
    "## MSE with Model/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "desirable-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "\n",
    "N, n_feature = 100, 5\n",
    "\n",
    "X = torch.rand((N,n_feature))\n",
    "Y = torch.rand((N,1))\n",
    "\n",
    "dataset    = TensorDataset(X,Y)         # create your datset\n",
    "dataloader = DataLoader(dataset)        # create your dataloader\n",
    "\n",
    "dense = nn.Linear(5,1)\n",
    "mseLoss = nn.MSELoss()\n",
    "\n",
    "for data, label in dataloader:\n",
    "    pred = dense(data)\n",
    "    loss = mseLoss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-macintosh",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "backed-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1450)\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "predictions = torch.rand(batch_size,1)\n",
    "\n",
    "labels       = torch.randint(0,2,(batch_size,1)).type(torch.float)\n",
    "\n",
    "BCE = nn.BCELoss()\n",
    "loss = BCE(predictions, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thrown-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1450)\n"
     ]
    }
   ],
   "source": [
    "loss = -(labels*torch.log(predictions)+(1-labels)*torch.log((1-predictions)))\n",
    "loss = torch.mean(loss)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-blackberry",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy with Model/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "devoted-sampling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4178, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(1.4087, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(1.6166, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "tensor(0.8954, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "N, n_feature = 100, 5\n",
    "\n",
    "t_weights = torch.tensor([1,2,3,4,5], dtype = torch.float32) \n",
    "t_bias    = torch.tensor([10], dtype = torch.float32) \n",
    "\n",
    "x = (torch.rand(N,n_feature) - 0.5)*10\n",
    "\n",
    "y = torch.sum(t_weights * x, axis = 1) + t_bias # Broadcasting\n",
    "y = nn.Sigmoid()(y)                             # !!\n",
    "y = (y>0.5).type(torch.int32).type(torch.float32)\n",
    "\n",
    "dataset    = TensorDataset(x,y)         # create your datset\n",
    "dataloader = DataLoader(dataset, batch_size=32)        # create your dataloader\n",
    "\n",
    "dense = nn.Linear(5,1)\n",
    "BCE   = nn.BCELoss()\n",
    "\n",
    "for data, label in dataloader:\n",
    "    pred = dense(data)\n",
    "    pred = nn.Sigmoid()(pred)\n",
    "    loss = BCE(pred.T[0], label)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-delhi",
   "metadata": {},
   "source": [
    "## Sparse Categorical Cross Entropy\n",
    "\n",
    "\n",
    "### nn.NLLLoss() \n",
    "    - softmax 처리된 output을 pred으로 넣음\n",
    "\n",
    "### nn.CrossEntropyLoss()\n",
    "    - mdoel output을 pred으로 넣으면 logSoftmax와 NLLLoss를 한번에 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "peripheral-delhi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3676, 0.6845, 0.1476, 0.4903, 0.5683],\n",
      "        [0.8334, 0.8973, 0.1140, 0.7494, 0.8158],\n",
      "        [0.3376, 0.8711, 0.6753, 0.0906, 0.4252],\n",
      "        [0.0569, 0.3270, 0.0133, 0.5710, 0.8103],\n",
      "        [0.3018, 0.4081, 0.4326, 0.9989, 0.1916],\n",
      "        [0.8806, 0.7782, 0.2183, 0.7067, 0.1660],\n",
      "        [0.9415, 0.9181, 0.6763, 0.2341, 0.4889],\n",
      "        [0.5138, 0.3190, 0.7849, 0.0192, 0.9273],\n",
      "        [0.8364, 0.0959, 0.2178, 0.8777, 0.9420],\n",
      "        [0.1746, 0.0997, 0.3741, 0.5302, 0.8699],\n",
      "        [0.7043, 0.5305, 0.6791, 0.1810, 0.1452],\n",
      "        [0.4638, 0.0299, 0.7129, 0.8548, 0.1126],\n",
      "        [0.6658, 0.0684, 0.5668, 0.4541, 0.5616],\n",
      "        [0.2108, 0.9812, 0.1475, 0.8910, 0.7815],\n",
      "        [0.6472, 0.5090, 0.0467, 0.6921, 0.9827],\n",
      "        [0.3367, 0.3324, 0.7482, 0.5901, 0.3973]])\n",
      "tensor([4, 1, 4, 3, 2, 0, 2, 4, 1, 3, 1, 3, 0, 4, 3, 0])\n",
      "tensor(1.5417)\n",
      "tensor([[0.3676, 0.6845, 0.1476, 0.4903, 0.5683],\n",
      "        [0.8334, 0.8973, 0.1140, 0.7494, 0.8158],\n",
      "        [0.3376, 0.8711, 0.6753, 0.0906, 0.4252],\n",
      "        [0.0569, 0.3270, 0.0133, 0.5710, 0.8103],\n",
      "        [0.3018, 0.4081, 0.4326, 0.9989, 0.1916],\n",
      "        [0.8806, 0.7782, 0.2183, 0.7067, 0.1660],\n",
      "        [0.9415, 0.9181, 0.6763, 0.2341, 0.4889],\n",
      "        [0.5138, 0.3190, 0.7849, 0.0192, 0.9273],\n",
      "        [0.8364, 0.0959, 0.2178, 0.8777, 0.9420],\n",
      "        [0.1746, 0.0997, 0.3741, 0.5302, 0.8699],\n",
      "        [0.7043, 0.5305, 0.6791, 0.1810, 0.1452],\n",
      "        [0.4638, 0.0299, 0.7129, 0.8548, 0.1126],\n",
      "        [0.6658, 0.0684, 0.5668, 0.4541, 0.5616],\n",
      "        [0.2108, 0.9812, 0.1475, 0.8910, 0.7815],\n",
      "        [0.6472, 0.5090, 0.0467, 0.6921, 0.9827],\n",
      "        [0.3367, 0.3324, 0.7482, 0.5901, 0.3973]])\n",
      "tensor([4, 1, 4, 3, 2, 0, 2, 4, 1, 3, 1, 3, 0, 4, 3, 0])\n",
      "tensor(1.5417)\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_class = 16, 5\n",
    "\n",
    "predictions = torch.rand(batch_size,n_class)                            # output \n",
    "labels      = torch.randint(0,n_class,(batch_size,)).type(torch.long)   # labels type => long\n",
    "print(predictions)\n",
    "print(labels)\n",
    "\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "print(cross_entropy_loss(predictions, labels))\n",
    "\n",
    "logSoftmax = nn.LogSoftmax(dim=1)\n",
    "predictions_logSoftmax = logSoftmax(predictions)\n",
    "print(predictions)\n",
    "print(labels)\n",
    "nll_loss = nn.NLLLoss()\n",
    "print(nll_loss(predictions_logSoftmax, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "sweet-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5417)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "predictions_Softmax = softmax(predictions)\n",
    "\n",
    "ce = 0\n",
    "for label, prediction in zip(labels, predictions_Softmax):\n",
    "    ce += - torch.log(prediction[label])\n",
    "ce /= batch_size\n",
    "print(ce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
