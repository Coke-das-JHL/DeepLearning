{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unusual-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominant-structure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape :  torch.Size([4, 8])\n",
      "<class 'generator'>\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8])\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (5): Sigmoid()\n",
      "  (6): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n",
      "\n",
      "Linear(in_features=10, out_features=64, bias=True)\n",
      "\n",
      "Sigmoid()\n",
      "\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "\n",
      "Sigmoid()\n"
     ]
    }
   ],
   "source": [
    "N, n_feature = 4, 10\n",
    "x = torch.rand((N, n_feature))\n",
    "\n",
    "model = nn.Sequential(\n",
    "          nn.Linear(10,64),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(64,32),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(32,16),\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(16,8),\n",
    "          nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "y = model(x)\n",
    "print('y shape : ', y.shape)\n",
    "\n",
    "\n",
    "# Weigh & Bias\n",
    "print(type(model.parameters()))         # generator : Parameter iterator를 생성\n",
    "parameters=[x.data for x in model.parameters()]\n",
    "# Layer 1 Weight & Bias\n",
    "print( parameters[0].shape )\n",
    "print( parameters[1].shape )\n",
    "# Layer 2 Weight & Bias\n",
    "print( parameters[2].shape )\n",
    "print( parameters[3].shape )\n",
    "# Layer 3 Weight & Bias\n",
    "print( parameters[4].shape )\n",
    "print( parameters[5].shape )\n",
    "# Layer 4 Weight & Bias\n",
    "print( parameters[6].shape )\n",
    "print( parameters[7].shape )\n",
    "\n",
    "# Layers\n",
    "print(model)\n",
    "print(model[0])\n",
    "print(model[1])\n",
    "print(model[2])\n",
    "print(model[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape :  torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):                # __init__() 에 신경망 레이어의 구성요소 정의\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(10,64)\n",
    "        self.fc2 = nn.Linear(64,32)\n",
    "        self.fc3 = nn.Linear(32,16)\n",
    "        self.fc4 = nn.Linear(16,8)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):             # __forward__ 에 호출 될 때 수행되는 연산 정의 \n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.act(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "y = model.forward(x)\n",
    "print('y shape : ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opponent-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape :  torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):    # Model 생성시 추가로 인수 받을 수 있음\n",
    "        super(MyModel, self).__init__()   # 상속받아야 하는 nn.Module Class 객체\n",
    "        layer1 = nn.Linear(x_dim, 64)\n",
    "        layer2 = nn.Linear(64, 32)\n",
    "        layer3 = nn.Linear(32, 16)\n",
    "        layer4 = nn.Linear(16, y_dim)\n",
    "        activation = nn.Sigmoid()\n",
    "        \n",
    "        self.module = nn.Sequential(\n",
    "            layer1,\n",
    "            activation,\n",
    "            layer2,\n",
    "            activation,\n",
    "            layer3,\n",
    "            activation,\n",
    "            layer4,\n",
    "            activation,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.module(x)\n",
    "        return y    \n",
    "    \n",
    "model = MyModel(10,8)\n",
    "y = model.forward(x)\n",
    "print('y shape : ', y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
